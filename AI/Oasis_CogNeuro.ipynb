{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pickle\n",
    "from preprocess import clean,split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(filename):\n",
    "    df=pd.read_csv(filename)\n",
    "\n",
    "    df = df.loc[df['Visit']==1] # consider only patients with 1 visit. \n",
    "    \n",
    "    df['M/F'] = df['M/F'].replace(['F','M'], [0,1]) # represent Male as 1 and Female as 0.\n",
    "    df['Group'] = df['Group'].replace(['Converted'], ['Demented']) # some patients converted to Demented.\n",
    "    df['Group'] = df['Group'].replace(['Demented', 'Nondemented'], [1,0]) # represent Demented as 1 and Non as 0.\n",
    "\n",
    "    df=df.dropna(axis=0,how='any') # drop rows with missing SES(socio-economic status) value.\n",
    "    df = df.drop(['MRI ID', 'Visit', 'Hand'], axis=1) # Drop unnecessary columns\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject ID  Group  MR Delay  M/F  Age  EDUC  SES  MMSE  CDR  eTIV   nWBV  \\\n",
      "0  OAS2_0001      0         0    1   87    14  2.0  27.0  0.0  1987  0.696   \n",
      "1  OAS2_0004      0         0    0   88    18  3.0  28.0  0.0  1215  0.710   \n",
      "2  OAS2_0005      0         0    1   80    12  4.0  28.0  0.0  1689  0.712   \n",
      "3  OAS2_0008      0         0    0   93    14  2.0  30.0  0.0  1272  0.698   \n",
      "4  OAS2_0009      1         0    1   68    12  2.0  27.0  0.5  1457  0.806   \n",
      "\n",
      "     ASF  \n",
      "0  0.883  \n",
      "1  1.444  \n",
      "2  1.039  \n",
      "3  1.380  \n",
      "4  1.205  \n"
     ]
    }
   ],
   "source": [
    "def split(df):\n",
    "\n",
    "    Y = df['Group'].values # Logistic target for model\n",
    "    X = df[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features used for prediction.\n",
    "\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X, Y, random_state=0)\n",
    "\n",
    "    # feature scaling\n",
    "    scaler = MinMaxScaler().fit(X_train) # scales values between 0 and 1.\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled,X_test_scaled,Y_train,Y_test\n",
    "    \n",
    "\n",
    "if __name__=='__main__':\n",
    "    print(clean('oasis_longitudinal.csv').head())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df=clean('oasis_longitudinal.csv')\n",
    "X_train,X_test,Y_train,Y_test=split(cleaned_df)\n",
    "\n",
    "logistic_model=LogisticRegression(C=10).fit(X_train,Y_train)\n",
    "forest_model = RandomForestClassifier(n_estimators=3, max_features=4, n_jobs=4, max_depth=5, random_state=0).fit(X_train,Y_train)\n",
    "tree_model = DecisionTreeClassifier(random_state=0, max_depth=1, criterion='gini').fit(X_train,Y_train)\n",
    "adaboost_model=AdaBoostClassifier(n_estimators=3, learning_rate=0.0001, random_state=0).fit(X_train,Y_train)\n",
    "\n",
    "pickle.dump(logistic_model, open('model_files/logistic.sav', 'wb'))\n",
    "pickle.dump(forest_model,open('model_files/forest.sav','wb'))\n",
    "pickle.dump(tree_model,open('model_files/tree.sav','wb'))\n",
    "pickle.dump(adaboost_model,open('model_files/adaboost.sav','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Accuracy = 0.8055555555555556\n",
      "Recall = 0.9411764705882353\n",
      "f1_score = 0.8205128205128205\n",
      "precesion = 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc, f1_score, precision_score\n",
    "import pickle\n",
    "from preprocess import clean,split\n",
    "\n",
    "def score(filename,disp=True):\n",
    "    cleaned_df=clean('oasis_longitudinal.csv')\n",
    "    _,X_test,_,Y_test=split(cleaned_df)\n",
    "\n",
    "    model=pickle.load(open(filename, 'rb'))\n",
    "    Y_pred=model.predict(X_test)\n",
    "    recall=recall_score(Y_test,Y_pred)\n",
    "    accuracy=accuracy_score(Y_test,Y_pred)\n",
    "    f1score = f1_score(Y_test,Y_pred)\n",
    "    pre = precision_score(Y_test,Y_pred)\n",
    "    if disp:\n",
    "        print(model)\n",
    "        print(f\"Accuracy = {accuracy}\")\n",
    "        print(f\"Recall = {recall}\")\n",
    "        print(f\"f1_score = {f1score}\")\n",
    "        print(f\"precesion = {pre}\")\n",
    "    return model\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    # load the trained model. if you don't want to display the scores of the model set the argument disp=False.\n",
    "    model=score('model_files/logistic.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
